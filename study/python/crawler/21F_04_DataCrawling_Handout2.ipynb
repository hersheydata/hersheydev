{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Naver Blog Crawling (basic)\n",
    "https://developers.naver.com/docs/search/blog/\n",
    "\n",
    "#### 1. 개인 application ID, secret 발급받기 \n",
    "#### 2. Python 활용시 블로그 검색 API 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "naver_client_id = \"S79oTS9dx6TONhrab83P\" #네이버 어플리케이션 ID 입력\n",
    "naver_client_secret = \"bV5K1PSVDD\"# 네이버 어플리케이션 SECRET 입력\n",
    "encText = urllib.parse.quote(\"수트패션\") # 검색할 단어 입력\n",
    "\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # json 결과  #검색어 qeury의 검색할 때 사용하는 url\n",
    "                                                                                                                  \n",
    "    # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과  \n",
    "                                                                       \n",
    "        \n",
    "request = urllib.request.Request(url)      \n",
    "request.add_header(\"X-Naver-Client-Id\",naver_client_id)  \n",
    "request.add_header(\"X-Naver-Client-Secret\",naver_client_secret)\n",
    "\n",
    "response = urllib.request.urlopen(request)  \n",
    "rescode = response.getcode()              #요청(request)을 반환(response)하는 것\n",
    "\n",
    "if(rescode==200):                        #서버가 요청을 제대로 처리했다는 뜻의 200\n",
    "    response_body = response.read()      #response.read()함수는 요청한 페이지를 읽어들인다는 의미\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Naver Blog Crawling (Advanced)\n",
    "https://developers.naver.com/docs/search/blog/\n",
    "\n",
    "#### 1. BeautifulSoup 사용하기 : HTML, XML 등의 문서를 구문분석하기 위한 파이썬 라이브러리\n",
    "#### 2. 블로그 수집하고, CSV파일로 저장하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "\n",
    "import re               #정규표현식 사용을 위한 라이브러리\n",
    "import json             #네이버API를 통해 가져온 JSON 파일을 처리하기 위한 라이브러리\n",
    "import math             #수학 라이브러리\n",
    "import requests         #http 통신을 사용\n",
    "import urllib.request   #웹과 관련된 내용을 처리하는 라이브러리: urllib\n",
    "import urllib.error     \n",
    "import urllib.parse       ##파싱(parse): 데이터를 특정 패턴이나 순서로 추출해 가공하는 것>> 파서(parser)로 웹페이지 구조를 읽어들임\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeaurifulSoup 설치  : 네이버 API는 블로그 일부 내용만 반환하여,크롤링 라이브러리인 BeautifulSoup를 설치하고 전체 블로그 URL로 접속하여 포스트 내용 전체를 가져와 저장\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_client_id = \"S79oTS9dx6TONhrab83P\" #네이버 어플리케이션 ID 입력\n",
    "naver_client_secret = \"bV5K1PSVDD\" # 네이버 어플리케이션 SECRET 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#블로그 개수 카운트\n",
    "#블로그 전체 개수를 가져오는 함수: get_blog_count()\n",
    "#query=검색 키워드\n",
    "\n",
    "def get_blog_count(query, display):\n",
    "    encode_query = urllib.parse.quote(query)\n",
    "    search_url = \"https://openapi.naver.com/v1/search/blog?query=\" + encode_query\n",
    "    request = urllib.request.Request(search_url)\n",
    "\n",
    "    request.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    request.add_header(\"X-naver-Client-Secret\", client_secret)\n",
    "    \n",
    "    response = urllib.request.urlopen(request)\n",
    "    response_code = response.getcode()\n",
    "\n",
    "    if response_code == 200:\n",
    "        response_body = response.read()\n",
    "        response_body_dict = json.loads(response_body.decode('utf-8'))\n",
    "\n",
    "        print(\"Last build date: \" + str(response_body_dict['lastBuildDate']))\n",
    "        print(\"Total: \" + str(response_body_dict['total']))\n",
    "        print(\"Start: \" + str(response_body_dict['start']))\n",
    "        print(\"Display: \" + str(response_body_dict['display']))\n",
    "\n",
    "        if response_body_dict['total'] == 0:\n",
    "            blog_count = 0\n",
    "        else:\n",
    "            blog_total = math.ceil(response_body_dict['total'] / int(display))\n",
    "\n",
    "            if blog_total >= 1000:\n",
    "                blog_count = 1000          #네이버에서는 검색에 대한 최대 1000개의 검색결과만 보여주기 때문에\n",
    "            else:\n",
    "                blog_count = blog_total\n",
    "\n",
    "            print(\"Blog total: \" + str(blog_total))\n",
    "            print(\"Blog count: \" + str(blog_count))\n",
    "        \n",
    "        return blog_count\n",
    "    \n",
    "    #(query, display) parameter 입력하여 get_blog_count 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_blog_count('패션', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그 내용 가져오는 코드\n",
    "\n",
    "def get_blog_post(query, display, start_index, sort):\n",
    "    global no, df\n",
    "    \n",
    "    encode_query = urllib.parse.quote(query)\n",
    "    search_url = \"https://openapi.naver.com/v1/search/blog?query=\" + encode_query + \"&display=\" + str(display) + \"&start=\" + str(start_index) + \"&sort=\" + sort\n",
    "\n",
    "    request = urllib.request.Request(search_url)\n",
    "\n",
    "    request.add_header(\"X-Naver-Client-Id\", naver_client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\", naver_client_secret)\n",
    "\n",
    "    response = urllib.request.urlopen(request)\n",
    "    response_code = response.getcode()\n",
    "\n",
    "    if response_code == 200:\n",
    "        response_body = response.read()\n",
    "        response_body_dict = json.loads(response_body.decode('utf-8'))\n",
    "        for item_index in range(0, len(response_body_dict['items'])):\n",
    "            try:\n",
    "                remove_html_tag = re.compile('<.*?>')\n",
    "                title = re.sub(remove_html_tag, '', response_body_dict['items'][item_index]['title'])\n",
    "                link = response_body_dict['items'][item_index]['link'].replace(\"amp;\", \"\")\n",
    "                description = re.sub(remove_html_tag, '', response_body_dict['items'][item_index]['description'])\n",
    "                blogger_name = response_body_dict['items'][item_index]['bloggername']\n",
    "                blogger_link = response_body_dict['items'][item_index]['bloggerlink']\n",
    "                post_date = response_body_dict['items'][item_index]['postdate']\n",
    "\n",
    "                no += 1\n",
    "                post_code = requests.get(link)\n",
    "                post_text = post_code.text\n",
    "                post_soup = BeautifulSoup(post_text, 'lxml')\n",
    "\n",
    "                blog_post_content_text = \"\"\n",
    "                for mainFrame in post_soup.select('iframe#mainFrame'):\n",
    "                    blog_post_url = \"http://blog.naver.com\" + mainFrame.get('src')\n",
    "                    blog_post_code = requests.get(blog_post_url)\n",
    "                    blog_post_text = blog_post_code.text\n",
    "                    blog_post_soup = BeautifulSoup(blog_post_text, 'lxml')\n",
    "                    \n",
    "                    for blog_post_content in blog_post_soup.find_all('div', class_='se-viewer'):\n",
    "                        blog_post_content_text = blog_post_content.get_text()\n",
    "                        \n",
    "                    for blog_post_content in blog_post_soup.find_all('div', class_='se_doc_viewer'):\n",
    "                        blog_post_content_text = blog_post_content.get_text()\n",
    " \n",
    "                    for blog_post_content in blog_post_soup.select('div#postViewArea'):\n",
    "                        blog_post_content_text = blog_post_content.get_text()\n",
    "\n",
    "                df.loc[no] = [title, link, description, blogger_name, blogger_link, post_date, blog_post_content_text]\n",
    "                print(\"#\", end='')\n",
    "                \n",
    "            except:\n",
    "                item_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(query, display, start_index, sort) 입력하여 get_blog_post 함수 테스트\n",
    "\n",
    "get_blog_post('수트패션', 10, 1, 'sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no = 0                 # 몇개의 포스트를 저장하였는지 세기 위한 index\n",
    "query = '수트패션'              # 검색을 원하는 문자열로서 UTF-8로 인코딩한다.\n",
    "display = 10            # 검색 결과 출력 건수 지정, 10(기본값),100(최대)\n",
    "start = 1              # 검색 시작 위치로 최대 1000까지 가능\n",
    "sort =  'sim'               \n",
    "\n",
    "df = pd.DataFrame(columns=(\"Title\", \"Link\", \"Description\", \"Blogger Name\", \"Blogger Link\", \"Post Date\", \"Post Contents\"))\n",
    "\n",
    "blog_count = get_blog_count(query, display)\n",
    "for start_index in range(start, blog_count + 1, display):  #for 함수는 반복함수 \n",
    "    get_blog_post(query, display, start_index, sort)\n",
    "    \n",
    "df.to_csv(\"21_suit_fashion.csv\".header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 불러와서 잘 저장되었는지 테스트\n",
    "\n",
    "data = pd.reac_csv('21_suit_fashion.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
